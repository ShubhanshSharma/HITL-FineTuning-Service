{
  "base_model": "meta-llama/Meta-Llama-3-8B-Instruct",
  "lora": {
    "r": 8,
    "alpha": 16,
    "dropout": 0.05,
    "target_modules": [
      "q_proj",
      "v_proj"
    ]
  },
  "training": {
    "epochs": 3,
    "batch_size": 4,
    "learning_rate": 0.0002,
    "seed": 42
  }
}